import json
import os
import re

import boto3
import gradio as gr
from botocore.config import Config
from dotenv import load_dotenv
from openai import OpenAI

from ape import APE
from translate import GuideBased

ape = APE()
rewrite = GuideBased()

load_dotenv()

# Initialize the LLM client
bedrock_runtime = boto3.client(
    service_name="bedrock-runtime", region_name=os.getenv("REGION_NAME")
)
client = OpenAI()

default_system = "you have profound knowledge and hands on experience in field of software engineering and artificial intelligence, you are also an experienced solution architect in Amazon Web Service and have expertise to impelment model application development with AWS in consdieration of well architect and industry best practice."
bedrock_default_system = default_system
openai_default_system = default_system


def generate_prompt(original_prompt, level):
    if level == "一次生成":
        result = rewrite(original_prompt)  # , cost
        return [
            gr.Textbox(
                label="我们为您生成的prompt",
                value=result,
                lines=3,
                show_copy_button=True,
                interactive=False,
            )
        ] + [gr.Textbox(visible=False)] * 2

    elif level == "多次生成":
        candidates = []
        for i in range(3):
            result = rewrite(original_prompt)
            candidates.append(result)
        judge_result = rewrite.judge(candidates)
        textboxes = []
        for i in range(3):
            is_best = "Y" if judge_result == i else "N"
            textboxes.append(
                gr.Textbox(
                    label=f"我们为您生成的prompt #{i+1} {is_best}",
                    value=candidates[i],
                    lines=3,
                    show_copy_button=True,
                    visible=True,
                    interactive=False,
                )
            )
        return textboxes


def ape_prompt(original_prompt, user_data):
    result = ape(initial_prompt, 1, json.loads(user_data))
    return [
        gr.Textbox(
            label="我们为您生成的prompt",
            value=result["prompt"],
            lines=3,
            show_copy_button=True,
            interactive=False,
        )
    ] + [gr.Textbox(visible=False)] * 2


def generate_bedrock_response(prompt, model_id):
    """
    This function generates a test dataset by invoking a model with a given prompt.

    Parameters:
    prompt (str): The user input prompt.

    Returns:
    matches (list): A list of questions generated by the model, each wrapped in <case></case> XML tags.
    """
    message = {
        "role": "user",
        "content": [
            # {"type": "image", "source": {"type": "base64", "media_type": "image/jpeg", "data": content_image}},
            {"type": "text", "text": prompt}
        ],
    }
    messages = [message]
    body = json.dumps(
        {
            "anthropic_version": "bedrock-2023-05-31",
            "max_tokens": 4000,
            "messages": messages,
            "system": bedrock_default_system,
        }
    )
    response = bedrock_runtime.invoke_model(body=body, modelId=model_id)
    response_body = json.loads(response.get("body").read())
    return response_body["content"][0]["text"]


def generate_openai_response(prompt, model_id):
    completion = client.chat.completions.create(
        model=model_id,
        messages=[
            {"role": "system", "content": openai_default_system},
            {"role": "user", "content": prompt},
        ],
    )
    return completion.choices[0].message.content


def evaluate_prompt(original_prompt, revised_prompt, openai_model_id, aws_model_id):
    openai_result = generate_openai_response(original_prompt, openai_model_id)
    aws_result = generate_bedrock_response(revised_prompt, aws_model_id)
    return openai_result, aws_result


def insert_kv(user_prompt, kv_string):
    # Split the key-value string by ';' to get individual pairs
    kv_pairs = kv_string.split(";")
    for pair in kv_pairs:
        if ":" in pair:
            key, value = pair.split(":", 1)  # Only split on the first ':'
            user_prompt = user_prompt.replace(f"{{{key}}}", value).replace(
                f"<{key}>", value
            )
    return user_prompt


def generate_revised_prompt(feedback, prompt, openai_response, aws_response):
    # Placeholder for generating a revised prompt based on the feedback
    pass


with gr.Blocks(
    title="Automatic Prompt Engineering",
    theme="soft",
    css="#textbox_id textarea {color: red}",
) as demo:
    with gr.Tab("Prompt 生成"):
        gr.Markdown("# Automatic Prompt Engineering")
        original_prompt = gr.Textbox(label="请输入您的原始prompt", lines=3)
        gr.Markdown("其中用户自定义变量使用{\{xxx\}}表示，例如{\{document\}}")
        with gr.Row():
            with gr.Column(scale=2):
                level = gr.Radio(
                    ["一次生成", "多次生成"], label="优化等级", value="一次生成"
                )
                b1 = gr.Button("优化prompt")
            with gr.Column(scale=2):
                user_data = gr.Textbox(label="测试数据JSON", lines=2)
                b2 = gr.Button("APE优化prompt")
        textboxes = []
        for i in range(3):
            t = gr.Textbox(
                label="我们为您生成的prompt",
                elem_id="textbox_id",
                lines=3,
                show_copy_button=True,
                interactive=False,
                visible=False if i > 0 else True,
            )
            textboxes.append(t)
        log = gr.Markdown("")
        b1.click(generate_prompt, inputs=[original_prompt, level], outputs=textboxes)
        b2.click(ape_prompt, inputs=[original_prompt, user_data], outputs=textboxes)
    with gr.Tab("Prompt 评估"):
        with gr.Row():
            user_prompt_orginal = gr.Textbox(label="请输入您的原始prompt", lines=3)
            kv_input = gr.Textbox(
                label="[可选]输入需要替换的模版参数",
                placeholder="参考格式: key1:value1;key2:value2",
                lines=2,
            )
            user_prompt_eval = gr.Textbox(label="请输入您要评估的prompt", lines=3)
            kv_input = gr.Textbox(
                label="[可选]输入需要替换的模版参数",
                placeholder="参考格式: key1:value1;key2:value2",
                lines=2,
            )
        with gr.Row():
            insert_button_original = gr.Button("替换原始模版参数")
            insert_button_original.click(
                insert_kv,
                inputs=[user_prompt_orginal, kv_input],
                outputs=user_prompt_orginal,
            )
            insert_button_revise = gr.Button("替换评估模版参数")
            insert_button_revise.click(
                insert_kv, inputs=[user_prompt_eval, kv_input], outputs=user_prompt_eval
            )
        with gr.Row():
            # https://platform.openai.com/docs/models/gpt-4-and-gpt-4-turbo
            openai_model_dropdown = gr.Dropdown(
                label="选择 OpenAI 模型",
                choices=[
                    "gpt-3.5-turbo",
                    "gpt-4-32k",
                    "gpt-4-1106-preview",
                    "gpt-4-turbo-preview",
                ],
                value="gpt-3.5-turbo",
            )
            # aws bedrock list-foundation-models --region us-east-1 --output json | jq -r '.modelSummaries[].modelId'
            aws_model_dropdown = gr.Dropdown(
                label="选择 AWS 模型",
                choices=[
                    "anthropic.claude-instant-v1:2:100k",
                    "anthropic.claude-instant-v1",
                    "anthropic.claude-v2:0:18k",
                    "anthropic.claude-v2:0:100k",
                    "anthropic.claude-v2:1:18k",
                    "anthropic.claude-v2:1:200k",
                    "anthropic.claude-v2:1",
                    "anthropic.claude-v2",
                    "anthropic.claude-3-sonnet-20240229-v1:0",
                    "anthropic.claude-3-haiku-20240307-v1:0",
                ],
                value="anthropic.claude-3-sonnet-20240229-v1:0",
            )
        evaluate_button = gr.Button("评估prompt")
        with gr.Row():
            openai_output = gr.Textbox(label="OpenAI 输出", lines=3, interactive=False)
            aws_output = gr.Textbox(
                label="AWS Bedrock 输出", lines=3, interactive=False
            )
        evaluate_button.click(
            evaluate_prompt,
            inputs=[
                user_prompt_orginal,
                user_prompt_eval,
                openai_model_dropdown,
                aws_model_dropdown,
            ],
            outputs=[openai_output, aws_output],
        )
        feedback_input = gr.Textbox(
            label="人工反馈", placeholder="请在此填入您的反馈", lines=3
        )
        revise_button = gr.Button("修正Prompt")
        revised_prompt_output = gr.Textbox(
            label="修正后的Prompt", lines=3, interactive=False
        )
        revise_button.click(
            generate_revised_prompt,
            inputs=[feedback_input, user_prompt_eval, openai_output, aws_output],
            outputs=revised_prompt_output,
        )

demo.launch()
